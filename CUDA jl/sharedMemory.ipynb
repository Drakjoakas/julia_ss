{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "using CUDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrizTranspuesta! (generic function with 1 method)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function matrizTranspuesta!(entrada,salida)\n",
    "    columna = threadIdx().x\n",
    "    fila    = threadIdx().y\n",
    "    univId  = (columna) + (fila-1) * blockDim().x\n",
    "    transId = (fila) + (columna -1) * blockDim().y\n",
    "    salida[transId] = entrada[univId]\n",
    "    return nothing\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6×10 Matrix{Int32}:\n",
       " 1   7  13  19  25  31  37  43  49  55\n",
       " 2   8  14  20  26  32  38  44  50  56\n",
       " 3   9  15  21  27  33  39  45  51  57\n",
       " 4  10  16  22  28  34  40  46  52  58\n",
       " 5  11  17  23  29  35  41  47  53  59\n",
       " 6  12  18  24  30  36  42  48  54  60"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "entrada_hst = zeros(Int32,6,10)\n",
    "for i in eachindex(entrada_hst)\n",
    "    entrada_hst[i] = i\n",
    "end\n",
    "entrada_hst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10×6 CuArray{Int64, 2, CUDA.Mem.DeviceBuffer}:\n",
       " 0  0  0  0  0  0\n",
       " 0  0  0  0  0  0\n",
       " 0  0  0  0  0  0\n",
       " 0  0  0  0  0  0\n",
       " 0  0  0  0  0  0\n",
       " 0  0  0  0  0  0\n",
       " 0  0  0  0  0  0\n",
       " 0  0  0  0  0  0\n",
       " 0  0  0  0  0  0\n",
       " 0  0  0  0  0  0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "entrada_dev = CuArray(entrada_hst)\n",
    "salida_dev = CuArray(zeros(Int64,10,6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CUDA.HostKernel{typeof(matrizTranspuesta!), Tuple{CuDeviceMatrix{Int32, 1}, CuDeviceMatrix{Int64, 1}}}(matrizTranspuesta!, CuContext(0x00000000662be020, instance cf70d06f966b64f1), CuModule(Ptr{Nothing} @0x0000000066789190, CuContext(0x00000000662be020, instance cf70d06f966b64f1)), CuFunction(Ptr{Nothing} @0x00000000668a43a0, CuModule(Ptr{Nothing} @0x0000000066789190, CuContext(0x00000000662be020, instance cf70d06f966b64f1))), CUDA.KernelState(Ptr{Nothing} @0x0000000604000000))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@sync @cuda threads=(6,10) matrizTranspuesta!(entrada_dev,salida_dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10×6 Matrix{Int64}:\n",
       "  1   2   3   4   5   6\n",
       "  7   8   9  10  11  12\n",
       " 13  14  15  16  17  18\n",
       " 19  20  21  22  23  24\n",
       " 25  26  27  28  29  30\n",
       " 31  32  33  34  35  36\n",
       " 37  38  39  40  41  42\n",
       " 43  44  45  46  47  48\n",
       " 49  50  51  52  53  54\n",
       " 55  56  57  58  59  60"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "salida_hst = Array(salida_dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix_transpose_shaerd (generic function with 1 method)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function matrix_transpose_shaerd(input, output)\n",
    "    sharedMemory = CUDA.CuStaticSharedArray(Int64,(blockDim(),blockDim()))\n",
    "\n",
    "    #global index\n",
    "    indexX = threadIdx().x + blockIdx().x * blockDim().x\n",
    "    indexY = threadIdx().y + blockIdx().y * blockDim().y \n",
    "\n",
    "    #transposed global index\n",
    "    tindexX = threadIdx().x + blockIdx().y * blockDim().x \n",
    "    tindexY = threadIdx().y + blockIdx().x * blockDim().y \n",
    "\n",
    "    #local index \n",
    "    localIndexX = threadIdx().x \n",
    "    localIndexY = threadIdx().y \n",
    "    index = indexY * N + indexX \n",
    "    transposedIndex = tindexY * N + tindexX\n",
    "\n",
    "    #transposed the matrix in shared memory \n",
    "    #global memory is read in coalesced fashion\n",
    "\n",
    "    sharedMemory[localIndexX][localIndexY] = input[index]\n",
    "    ##syncthreads() ?\n",
    "    output[transposedIndex] = sharedMemory[localIndexY][localIndexX]\n",
    "end\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.6.5",
   "language": "julia",
   "name": "julia-1.6"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.6.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
