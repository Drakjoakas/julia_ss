{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multiplicación de Matrices utilizando CUDA.jl y KernelAbstractions.jl\n",
    "\n",
    "Realizaremos un programa que ejecute la multiplicación de matrices de manera paralela usando las bibliotecas `CUDA.jl` y `KernelAbstractions` para comparar su funcionamiento, implementación y resultados.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "using KernelAbstractions, CUDA, CUDAKernels, Test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## KernelAbstractions\n",
    "\n",
    "Comenzamos definiendo el kernel usando el macro `@kernel` y definiendo la lógica de nuestro programa."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "@kernel function matmul_kernel_ka!(a, b, c)\n",
    "    #Obtenemos los índices globales en forma de tupla\n",
    "    i, j = @index(Global, NTuple)\n",
    "\n",
    "    #variable temporal para hacer la suma de los índices\n",
    "    \n",
    "    tmp_sum = zero(eltype(c))\n",
    "\n",
    "    #obtenemos el resultado que irá en la posición c[i,j] \n",
    "    for k = 1:size(a)[2]\n",
    "        tmp_sum += a[i,k] * b[k,j]\n",
    "    end\n",
    "\n",
    "    #asignamos el resultado\n",
    "    c[i,j] = tmp_sum\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos a crear una función para invocar el kernel y evitar que se lance con errores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matmul_ka! (generic function with 1 method)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "function matmul_ka!(a,b,c)\n",
    "    if size(a)[2] != size(b)[1]\n",
    "        println(\"El tamaño de las matrices no coincide!\")\n",
    "        return nothing\n",
    "    end\n",
    "    if isa(a, Array)\n",
    "        kernel! = matmul_kernel_ka!(CPU(),4)\n",
    "    else\n",
    "        kernel! = matmul_kernel_ka!(CUDADevice(), 256)\n",
    "    end\n",
    "    kernel!(a,b,c,ndrange=size(c))\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para probar la ejecución del kernel, definiremos primero los 3 arreglos donde estarán nuestros operandos y el resultado. Luego se lo pasaremos a la función en forma de `CuArray` para que se ejecute dentro del GPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = rand(256,123);\n",
    "b = rand(123,45);\n",
    "c = zeros(256,45);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "if has_cuda_gpu()\n",
    "    d_a = CuArray(a)\n",
    "    d_b = CuArray(b)\n",
    "    d_c = CuArray(c)\n",
    "\n",
    "    ev = matmul_ka!(d_a, d_b, d_c)\n",
    "    wait(ev)\n",
    "\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CUDA.jl\n",
    "\n",
    "Para realizar el programa en `CUDA.jl` se necesita la biblioteca `CUDA` (que ya incluimos para hacer uso de `CuArray`) y definir el kernel sin necesidad del macro `@kernel`. Así mismo, la obtención del índice se hace usando las funciones `threadIdx()`, `blockIdx()` y `blockDim()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matmul_kernel_cu! (generic function with 1 method)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "function matmul_kernel_cu!(a,b,c)\n",
    "    i = threadIdx().x + (blockIdx().x -1) * blockDim().x\n",
    "    j = threadIdx().y + (blockIdx().y -1) * blockDim().y \n",
    "\n",
    "    tmp_sum = zero(eltype(c))\n",
    "\n",
    "    for k = 1:size(a)[2]\n",
    "        tmp_sum += a[i,k] * b[k,j]\n",
    "    end\n",
    "\n",
    "    c[i,j] = tmp_sum\n",
    "    return nothing\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como se puede ver, el kernel es prácticamente igual con la única diferencia siendo la manera de obtener los índices `i` y `j`.\n",
    "\n",
    "Para ejecutar el kernel, se usa la macro @cuda especificando el número de hilos y bloques."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_a = CUDA.rand(256,256);\n",
    "d_b = CUDA.rand(256,256);\n",
    "d_c = CuArray(zeros(256,256));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matmul_cu (generic function with 1 method)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "function matmul_cu(a,b,c)\n",
    "    if size(a)[2] != size(b)[1]\n",
    "        println(\"El tamaño de las matrices no coincide.\")\n",
    "        return nothing\n",
    "    end\n",
    "\n",
    "    m,n = size(c)\n",
    "    n_threads = (32,32)\n",
    "    n_blocks = (div(m,32),div(m,32))\n",
    "    @sync @cuda threads=n_threads blocks=n_blocks matmul_kernel_cu!(a,b,c)\n",
    "\n",
    "end\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[32m\u001b[1mTest Passed\u001b[22m\u001b[39m"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "matmul_cu(d_a,d_b,d_c)\n",
    "\n",
    "@test isapprox(Array(d_c), Array(d_a)*Array(d_b))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.6.2",
   "language": "julia",
   "name": "julia-1.6"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.6.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
