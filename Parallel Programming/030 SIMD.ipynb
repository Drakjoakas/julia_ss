{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SIMD: The parallelism that can (sometimes) happen automatically\n",
    "\n",
    "SIMD: Single-instruction, multiple data\n",
    "\n",
    "(Also confusingly called vectorization)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The architecture\n",
    "\n",
    "Instead of computing four sums sequentially:\n",
    "\n",
    "\\begin{align}\n",
    "x_1 + y_1 &\\rightarrow z_1 \\\\\n",
    "x_2 + y_2 &\\rightarrow z_2 \\\\\n",
    "x_3 + y_3 &\\rightarrow z_3 \\\\\n",
    "x_4 + y_4 &\\rightarrow z_4\n",
    "\\end{align}\n",
    "\n",
    "Modern processors have vector processing units that can do it all at once:\n",
    "\n",
    "$$\n",
    "\\left(\\begin{array}{cc}\n",
    "x_1 \\\\\n",
    "x_2 \\\\\n",
    "x_3 \\\\\n",
    "x_4\n",
    "\\end{array}\\right)\n",
    "+\n",
    "\\left(\\begin{array}{cc}\n",
    "y_1 \\\\\n",
    "y_2 \\\\\n",
    "y_3 \\\\\n",
    "y_4\n",
    "\\end{array}\\right)\n",
    "\\rightarrow\n",
    "\\left(\\begin{array}{cc}\n",
    "z_1 \\\\\n",
    "z_2 \\\\\n",
    "z_3 \\\\\n",
    "z_4\n",
    "\\end{array}\\right)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Making it happen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Simple task: compute the sum of a vector:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "49987.295795696285"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A = rand(100_000)\n",
    "function simplesum(A)\n",
    "    result = zero(eltype(A))\n",
    "    for i in eachindex(A)\n",
    "        @inbounds result += A[i]\n",
    "    end\n",
    "    return result\n",
    "end\n",
    "\n",
    "simplesum(A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  71.600 μs (0 allocations: 0 bytes)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "49987.295795696285"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "using BenchmarkTools\n",
    "@btime simplesum($A)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, is that good?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  9.100 μs (0 allocations: 0 bytes)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "49987.2957956958"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@btime sum($A)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We're slower that the builtin `sum` — and we're getting a different answer, too! Let's look at what happens with a 32-bit float instead of a 64 bit one. Each element has half the number of bits, so lets also double the length (so the total number of bits processed remains constant)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  143.100 μs (0 allocations: 0 bytes)\n",
      "  9.900 μs (0 allocations: 0 bytes)\n"
     ]
    }
   ],
   "source": [
    "A32 = rand(Float32, length(A)*2)\n",
    "@btime simplesum($A32)\n",
    "@btime sum($A32);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's even worse! What's going on here?  We're seeing an even multiple number\n",
    "difference in our performance — perhaps Julia's builtin sum is using some\n",
    "parallelism? Let's try using SIMD ourselves:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  8.333 μs (0 allocations: 0 bytes)\n",
      "  8.233 μs (0 allocations: 0 bytes)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "100023.03f0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function simdsum(A)\n",
    "    result = zero(eltype(A))\n",
    "    @simd for i in eachindex(A)\n",
    "        @inbounds result += A[i]\n",
    "    end\n",
    "    return result\n",
    "end\n",
    "@btime simdsum($A)\n",
    "@btime simdsum($A32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What did that do and why don't we always use `@simd for` — or why doesn't Julia\n",
    "just always use `@simd` for every `for` loop automatically?  Look at the values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(49987.295795696285, 49987.29579569581, 49987.2957956958)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "simplesum(A), simdsum(A), sum(A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100022.11f0, 100023.03f0, 100023.05f0)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "simplesum(A32), simdsum(A32), sum(A32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Why aren't they the same?\n",
    "\n",
    "Without `@simd`, Julia is doing _exactly_ what we told it to do: it's taking\n",
    "each element of our array and adding it to a big pile sequentially. Our answer\n",
    "is smaller than what Julia's builtin `sum` thinks it is: that's because as our\n",
    "pile gets bigger we begin losing the lower bits of each element that we're\n",
    "adding, and those small losses begin to add up!\n",
    "\n",
    "The `@simd` macro tells Julia that it can re-arrange floating point additions —\n",
    "even if it would change the answer. Depending on your CPU, this may lead to 2x or 4x\n",
    "or even 8x parallelism. Essentially, Julia is computing independent sums for\n",
    "the even indices and the odd indices simultaneously:\n",
    "\n",
    "\\begin{align}\n",
    "odds &\\leftarrow 0 \\\\\n",
    "evens &\\leftarrow 0 \\\\\n",
    "\\text{loop}&\\ \\text{odd}\\ i: \\\\\n",
    "    &\\left(\\begin{array}{cc}\n",
    "odds \\\\\n",
    "evens\n",
    "\\end{array}\\right)\n",
    "\\leftarrow\n",
    "\\left(\\begin{array}{cc}\n",
    "odds \\\\\n",
    "evens\n",
    "\\end{array}\\right)\n",
    "+\n",
    "\\left(\\begin{array}{cc}\n",
    "x_{i} \\\\\n",
    "x_{i+1}\n",
    "\\end{array}\\right) \\\\\n",
    "total &\\leftarrow evens + odds\n",
    "\\end{align}\n",
    "\n",
    "In many cases, Julia can and does know that a for-loop can be SIMD-ed and it\n",
    "will take advantage of this by default!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  8.300 μs (0 allocations: 0 bytes)\n",
      "  8.933 μs (0 allocations: 0 bytes)\n",
      "  8.200 μs (0 allocations: 0 bytes)\n",
      "  8.167 μs (0 allocations: 0 bytes)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1099928"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "B = rand(1:10, 100_000)\n",
    "@btime simplesum($B)\n",
    "@btime sum($B)\n",
    "B32 = rand(Int32(1):Int32(10), length(B)*2)\n",
    "@btime simplesum($B32)\n",
    "@btime simdsum($B32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How can we see if something is getting vectorized?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@code_llvm simdsum(A32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So what are the challenges?\n",
    "\n",
    "* Biggest hurdle is that you have to convince Julia and LLVM that it's able to\n",
    "  use SIMD instructions for your given algorithm. That's not always possible.\n",
    "* There are lots of limitations of what can and cannot be SIMD-ed:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/latex": [
       "\\begin{verbatim}\n",
       "@simd\n",
       "\\end{verbatim}\n",
       "Annotate a \\texttt{for} loop to allow the compiler to take extra liberties to allow loop re-ordering\n",
       "\n",
       "\\begin{quote}\n",
       "\\textbf{warning}\n",
       "\n",
       "Warning\n",
       "\n",
       "This feature is experimental and could change or disappear in future versions of Julia. Incorrect use of the \\texttt{@simd} macro may cause unexpected results.\n",
       "\n",
       "\\end{quote}\n",
       "The object iterated over in a \\texttt{@simd for} loop should be a one-dimensional range. By using \\texttt{@simd}, you are asserting several properties of the loop:\n",
       "\n",
       "\\begin{itemize}\n",
       "\\item It is safe to execute iterations in arbitrary or overlapping order, with special consideration for reduction variables.\n",
       "\n",
       "\n",
       "\\item Floating-point operations on reduction variables can be reordered, possibly causing different results than without \\texttt{@simd}.\n",
       "\n",
       "\\end{itemize}\n",
       "In many cases, Julia is able to automatically vectorize inner for loops without the use of \\texttt{@simd}. Using \\texttt{@simd} gives the compiler a little extra leeway to make it possible in more situations. In either case, your inner loop should have the following properties to allow vectorization:\n",
       "\n",
       "\\begin{itemize}\n",
       "\\item The loop must be an innermost loop\n",
       "\n",
       "\n",
       "\\item The loop body must be straight-line code. Therefore, \\href{@ref}{\\texttt{@inbounds}} is   currently needed for all array accesses. The compiler can sometimes turn   short \\texttt{\\&\\&}, \\texttt{||}, and \\texttt{?:} expressions into straight-line code if it is safe   to evaluate all operands unconditionally. Consider using the \\href{@ref}{\\texttt{ifelse}}   function instead of \\texttt{?:} in the loop if it is safe to do so.\n",
       "\n",
       "\n",
       "\\item Accesses must have a stride pattern and cannot be \"gathers\" (random-index   reads) or \"scatters\" (random-index writes).\n",
       "\n",
       "\n",
       "\\item The stride should be unit stride.\n",
       "\n",
       "\\end{itemize}\n",
       "\\begin{quote}\n",
       "\\textbf{note}\n",
       "\n",
       "Note\n",
       "\n",
       "The \\texttt{@simd} does not assert by default that the loop is completely free of loop-carried memory dependencies, which is an assumption that can easily be violated in generic code. If you are writing non-generic code, you can use \\texttt{@simd ivdep for ... end} to also assert that:\n",
       "\n",
       "\\end{quote}\n",
       "\\begin{itemize}\n",
       "\\item There exists no loop-carried memory dependencies\n",
       "\n",
       "\n",
       "\\item No iteration ever waits on a previous iteration to make forward progress.\n",
       "\n",
       "\\end{itemize}\n"
      ],
      "text/markdown": [
       "```\n",
       "@simd\n",
       "```\n",
       "\n",
       "Annotate a `for` loop to allow the compiler to take extra liberties to allow loop re-ordering\n",
       "\n",
       "!!! warning\n",
       "    This feature is experimental and could change or disappear in future versions of Julia. Incorrect use of the `@simd` macro may cause unexpected results.\n",
       "\n",
       "\n",
       "The object iterated over in a `@simd for` loop should be a one-dimensional range. By using `@simd`, you are asserting several properties of the loop:\n",
       "\n",
       "  * It is safe to execute iterations in arbitrary or overlapping order, with special consideration for reduction variables.\n",
       "  * Floating-point operations on reduction variables can be reordered, possibly causing different results than without `@simd`.\n",
       "\n",
       "In many cases, Julia is able to automatically vectorize inner for loops without the use of `@simd`. Using `@simd` gives the compiler a little extra leeway to make it possible in more situations. In either case, your inner loop should have the following properties to allow vectorization:\n",
       "\n",
       "  * The loop must be an innermost loop\n",
       "  * The loop body must be straight-line code. Therefore, [`@inbounds`](@ref) is   currently needed for all array accesses. The compiler can sometimes turn   short `&&`, `||`, and `?:` expressions into straight-line code if it is safe   to evaluate all operands unconditionally. Consider using the [`ifelse`](@ref)   function instead of `?:` in the loop if it is safe to do so.\n",
       "  * Accesses must have a stride pattern and cannot be \"gathers\" (random-index   reads) or \"scatters\" (random-index writes).\n",
       "  * The stride should be unit stride.\n",
       "\n",
       "!!! note\n",
       "    The `@simd` does not assert by default that the loop is completely free of loop-carried memory dependencies, which is an assumption that can easily be violated in generic code. If you are writing non-generic code, you can use `@simd ivdep for ... end` to also assert that:\n",
       "\n",
       "\n",
       "  * There exists no loop-carried memory dependencies\n",
       "  * No iteration ever waits on a previous iteration to make forward progress.\n"
      ],
      "text/plain": [
       "\u001b[36m  @simd\u001b[39m\n",
       "\n",
       "  Annotate a \u001b[36mfor\u001b[39m loop to allow the compiler to take extra liberties to allow\n",
       "  loop re-ordering\n",
       "\n",
       "\u001b[33m\u001b[1m  │ \u001b[22m\u001b[39m\u001b[33m\u001b[1mWarning\u001b[22m\u001b[39m\n",
       "\u001b[33m\u001b[1m  │\u001b[22m\u001b[39m\n",
       "\u001b[33m\u001b[1m  │\u001b[22m\u001b[39m  This feature is experimental and could change or disappear in\n",
       "\u001b[33m\u001b[1m  │\u001b[22m\u001b[39m  future versions of Julia. Incorrect use of the \u001b[36m@simd\u001b[39m macro may\n",
       "\u001b[33m\u001b[1m  │\u001b[22m\u001b[39m  cause unexpected results.\n",
       "\n",
       "  The object iterated over in a \u001b[36m@simd for\u001b[39m loop should be a one-dimensional\n",
       "  range. By using \u001b[36m@simd\u001b[39m, you are asserting several properties of the loop:\n",
       "\n",
       "    •  It is safe to execute iterations in arbitrary or overlapping\n",
       "       order, with special consideration for reduction variables.\n",
       "\n",
       "    •  Floating-point operations on reduction variables can be reordered,\n",
       "       possibly causing different results than without \u001b[36m@simd\u001b[39m.\n",
       "\n",
       "  In many cases, Julia is able to automatically vectorize inner for loops\n",
       "  without the use of \u001b[36m@simd\u001b[39m. Using \u001b[36m@simd\u001b[39m gives the compiler a little extra\n",
       "  leeway to make it possible in more situations. In either case, your inner\n",
       "  loop should have the following properties to allow vectorization:\n",
       "\n",
       "    •  The loop must be an innermost loop\n",
       "\n",
       "    •  The loop body must be straight-line code. Therefore, \u001b[36m@inbounds\u001b[39m is\n",
       "       currently needed for all array accesses. The compiler can\n",
       "       sometimes turn short \u001b[36m&&\u001b[39m, \u001b[36m||\u001b[39m, and \u001b[36m?:\u001b[39m expressions into straight-line\n",
       "       code if it is safe to evaluate all operands unconditionally.\n",
       "       Consider using the \u001b[36mifelse\u001b[39m function instead of \u001b[36m?:\u001b[39m in the loop if it\n",
       "       is safe to do so.\n",
       "\n",
       "    •  Accesses must have a stride pattern and cannot be \"gathers\"\n",
       "       (random-index reads) or \"scatters\" (random-index writes).\n",
       "\n",
       "    •  The stride should be unit stride.\n",
       "\n",
       "\u001b[36m\u001b[1m  │ \u001b[22m\u001b[39m\u001b[36m\u001b[1mNote\u001b[22m\u001b[39m\n",
       "\u001b[36m\u001b[1m  │\u001b[22m\u001b[39m\n",
       "\u001b[36m\u001b[1m  │\u001b[22m\u001b[39m  The \u001b[36m@simd\u001b[39m does not assert by default that the loop is completely\n",
       "\u001b[36m\u001b[1m  │\u001b[22m\u001b[39m  free of loop-carried memory dependencies, which is an assumption\n",
       "\u001b[36m\u001b[1m  │\u001b[22m\u001b[39m  that can easily be violated in generic code. If you are writing\n",
       "\u001b[36m\u001b[1m  │\u001b[22m\u001b[39m  non-generic code, you can use \u001b[36m@simd ivdep for ... end\u001b[39m to also\n",
       "\u001b[36m\u001b[1m  │\u001b[22m\u001b[39m  assert that:\n",
       "\n",
       "    •  There exists no loop-carried memory dependencies\n",
       "\n",
       "    •  No iteration ever waits on a previous iteration to make forward\n",
       "       progress."
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@doc @simd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* You do need to think through the consequences of re-ordering your algorithm."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A slightly trickier case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "using BenchmarkTools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "true"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function diff!(A, B)\n",
    "    A[1] = B[1]\n",
    "    for i in 2:length(A)\n",
    "        @inbounds A[i] = B[i] - B[i-1]\n",
    "    end\n",
    "    return A\n",
    "end\n",
    "A = zeros(Float32, 100_000)\n",
    "B = rand(Float32, 100_000)\n",
    "\n",
    "diff!(A, B)\n",
    "[B[1];diff(B)] == A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  7.900 μs (0 allocations: 0 bytes)\n",
      "  25.300 μs (2 allocations: 390.70 KiB)\n"
     ]
    }
   ],
   "source": [
    "@btime diff!($A, $B)\n",
    "@btime diff($B);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But what happens if we do it in-place?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  262.400 μs (0 allocations: 0 bytes)\n"
     ]
    }
   ],
   "source": [
    "Bcopy = copy(B)\n",
    "@btime diff!($Bcopy, $Bcopy);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What happened?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@code_llvm diff!(A, B)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can manually assert that arrays don't alias (or have any loop-dependencies),\n",
    "with the very special `@simd ivdep` flag, but this can be disastrous:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  7.800 μs (0 allocations: 0 bytes)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "false"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function unsafe_diff!(A, B)\n",
    "    A[1] = B[1]\n",
    "    @simd ivdep for i in 2:length(A)\n",
    "        @inbounds A[i] = B[i] - B[i-1]\n",
    "    end\n",
    "    return A\n",
    "end\n",
    "@btime unsafe_diff!($A, $B)\n",
    "[B[1];diff(B)] == A\n",
    "Bcopy = copy(B)\n",
    "unsafe_diff!(Bcopy, Bcopy)\n",
    "[B[1];diff(B)] == Bcopy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you really want to get your hands dirty, you can use the [SIMD.jl](https://github.com/eschnett/SIMD.jl)\n",
    "package to manually specify those `<8 x float>` things that LLVM generates.\n",
    "BUT: this is tricky and a pain; often it's just to be aware of what makes\n",
    "Julia code automatically SIMD-able, some of the cases where it may fail, and\n",
    "how to check its work."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SIMD\n",
    "\n",
    "* Exploits built-in parallelism in a processor\n",
    "* Best for small, tight innermost loops\n",
    "* Often happens automatically if you're careful\n",
    "    * Follow the [perforance best practices](https://docs.julialang.org/en/v1/manual/performance-tips/)\n",
    "    * `@inbounds` any array acesses\n",
    "    * No branches or (non-inlined) function calls\n",
    "* Can use `@simd` to allow Julia to break some rules to make it happen\n",
    "    * But be careful, especially with `@simd ivdep`!\n",
    "* Depending on processor and types involved, can yield 2-16x gains with extraordinarily little overhead\n",
    "    * Smaller datatypes can improve this further; use `Float32` instead of `Float64`\n",
    "      if possible, `Int32` instead of `Int64`, etc.\n",
    "    * When buying a new processor, look for [AVX-512](https://en.wikichip.org/wiki/x86/avx-512) support"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.6.5",
   "language": "julia",
   "name": "julia-1.6"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 3
}
